# -*- coding: utf-8 -*-
"""Side_Effect.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1jnf5jOh1hmUjefSAc6C4Ju693SmWY6cj

# Gerekli Kütüphanelerin İçe Aktarımı
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

"""# Makine Öğrenmesi Paketleri"""

from sklearn import model_selection
from sklearn.metrics import classification_report
from sklearn.metrics import confusion_matrix
from sklearn.metrics import accuracy_score

"""# Veri Kümesinin Okunması ve Görüntülenmesi"""

data=pd.read_excel('/content/side_effect_data 1.xlsx')

data.head()

"""# Veri Kümesinin şeklini Bulma"""

data.shape

"""# Temel bilgiler"""

data.info()

"""# Sayısal özelliklerin seçilmesi"""

numerical_data = data.select_dtypes(include='number')
numerical_features=numerical_data.columns.tolist()
print(f'There are {len(numerical_features)} numerical features:', '\n')
print(numerical_features)

"""# İstatistiksel Özet"""

data.describe()

numerical_data.hist(figsize=(8,8))
plt.show()

numerical_data.nunique()

"""# Kategorik özelliklerin seçilmesi"""

categorical_data=data.select_dtypes(include= 'object')
categorical_features=categorical_data.columns.tolist()
print(f'There are {len(categorical_features)} categorical features:', '\n')
print(categorical_features)

"""# Kategorik özelliklerin özet satistikleri"""

categorical_data.describe(include='object')

"""# Plotting a count plot on 'Cinsiyet'"""

data['Cinsiyet'].value_counts()
plt.figure(figsize=(5,5))
sns.countplot(x='Cinsiyet',data=data,palette="icefire",hue='Cinsiyet')
plt.title("Cinsiyet Ortalaması",fontsize=18)
plt.xticks(rotation=0)

"""# Plotting a count plot on 'İL'"""

data["Il"].value_counts()

plt.figure(figsize=(6,6))
sns.countplot(x='Il',data=data) #
plt.title("iL Ortalaması",fontsize=18 )
plt.xticks(rotation=45)

"""# Verilerdeki ilk 20 ilaç isminin sayım grafiği"""

data['Ilac_Adi'].value_counts().head(20).plot(kind='bar')
plt.rcParams['figure.figsize']=(10,7)
plt.show()

data['Ilac_Adi'].value_counts().head(20)

"""#YAN ETKİLER üzerine bir pasta grafiği çizme"""

plt.figure(figsize=(8, 6))
plt.pie(data['Yan_Etki'].value_counts(), labels=data['Yan_Etki'].value_counts().keys(), autopct='%1.1f%%', startangle=140)
plt.title('Yan Etki Sayısı', fontsize=18)
plt.axis('equal')  # Equal aspect ratio ensures the pie is drawn as a circle.

plt.show()

data.isna().sum()

""" # Her sütun için medyan değerini ayrı ayrı hesaplaması"""

median_value_kilo = data['Kilo'].median()
median_value_boy = data['Boy'].median()


data['Kilo'].fillna(median_value_kilo, inplace=True)
data['Boy'].fillna(median_value_boy, inplace=True)

mode_value = data['Cinsiyet'].mode()[0]
data['Cinsiyet'].fillna(mode_value, inplace=True)

data.isnull().sum()

graph=data.select_dtypes(include=['float64'])
graph.boxplot(figsize=(10,5))
plt.show()

data=data.drop(['Kullanici_id','Dogum_Tarihi','Uyruk','Il','Ilac_Baslangic_Tarihi','Ilac_Bitis_Tarihi','Yan_Etki_Bildirim_Tarihi'],axis=1)
data.head()

"""# Label Encoder"""

from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()

attr = []
for i in data.columns:
    if data[i].dtype == 'object':
        attr.append(i)

for i in attr:
    data[i] = le.fit_transform(data[i])

data.head()

"""# Bir korelasyon ısı haritası çizme"""

corrmatrix = data.corr()
plt.subplots(figsize=(14,8))
sns.heatmap(corrmatrix,vmin=-0.4 , vmax=0.9, annot=True, cmap='YlGnBu' , linewidth=0.2)

x = data.drop('Yan_Etki',axis=1)

y = data['Yan_Etki']

from sklearn.preprocessing import MinMaxScaler

scaler = MinMaxScaler()

x_scaled = scaler.fit_transform(x)

x_scaled=pd.DataFrame(x_scaled,columns=x.columns)

x_scaled.head()

from sklearn.model_selection import train_test_split

x_train, x_test, y_train, y_test = train_test_split(x_scaled, y, test_size=0.25, random_state=42)

from sklearn.linear_model import LogisticRegression

from sklearn.metrics import accuracy_score, classification_report

lr_model = LogisticRegression(random_state=42)
lr_model.fit(x_train, y_train)

lr_y_pred = lr_model.predict(x_test)

"""# Model Değerlendirmesi"""

print("Logistic Regression:")
print("Accuracy:", accuracy_score(y_test, lr_y_pred))
print(classification_report(y_test, lr_y_pred))

from sklearn.ensemble import RandomForestClassifier

rf_model = RandomForestClassifier(random_state=42)
rf_model.fit(x_train, y_train)

rf_y_pred = rf_model.predict(x_test)

print("Random Forest:")
print("Accuracy:", accuracy_score(y_test, rf_y_pred))
print(classification_report(y_test, rf_y_pred))

from sklearn.tree import DecisionTreeClassifier

dt_model = DecisionTreeClassifier(random_state=42)
dt_model.fit(x_train, y_train)

dt_y_pred = dt_model.predict(x_test)

print("Decision Tree:")
print("Accuracy:", accuracy_score(y_test, dt_y_pred))
print(classification_report(y_test, dt_y_pred))

from sklearn.neighbors import KNeighborsClassifier

metric_k=[]
neighbors=np.arange(3,15)

for k in neighbors:
  knn_model=KNeighborsClassifier(n_neighbors=k,metric='euclidean')
  knn_model.fit(x_train,y_train)

  knn_y_pred=knn_model.predict(x_test)
  acc=accuracy_score(y_test,knn_y_pred)
  metric_k.append(acc)

plt.plot(neighbors,metric_k,'o-')
plt.xlabel('k')
plt.ylabel('Accuracy')
plt.grid()

knn_model=KNeighborsClassifier(n_neighbors=3,metric='euclidean')
knn_model.fit(x_train,y_train)

knn_y_pred=knn_model.predict(x_test)

print("KNN Model:")
print("Accuracy:", accuracy_score(y_test, knn_y_pred))
print(classification_report(y_test, knn_y_pred))

from sklearn.naive_bayes import GaussianNB

gnb_model = GaussianNB()

gnb_model.fit(x_train, y_train)

gnb_y_pred = gnb_model.predict(x_test)

print("GNB Model:")
print("Accuracy:", accuracy_score(y_test, gnb_y_pred))
print(classification_report(y_test, gnb_y_pred))

from sklearn.model_selection import RandomizedSearchCV

param_dist = {
    'max_depth': [None] + list(np.arange(2, 20)),
    'min_samples_split': list(np.arange(2, 11)),
    'min_samples_leaf': list(np.arange(1, 11)),
    'criterion': ['gini', 'entropy']
}

dt_model = DecisionTreeClassifier(random_state=42)

random_search = RandomizedSearchCV( dt_model,
    param_distributions=param_dist,
    n_iter=100,
    cv=5,
    random_state=42
)

random_search.fit(x_train, y_train)

best_params = random_search.best_params_
best_dt = random_search.best_estimator_

print("Best parameters:", best_params)

predictions = best_dt.predict(x_test)

print("Randomsearch Model:")
print("Accuracy:", accuracy_score(y_test, predictions))
print(classification_report(y_test, predictions))

"""# Modellerin Kaydı"""

import pickle
dosya ="RandomizedSearchCV"
pickle.dump(best_dt,open(dosya,'wb'))